# 部署和分发分析和模型

我们在 Go 中实现了各种模型，包括回归、分类、聚类等等。您还了解了开发机器学习模型的一些过程。我们的模型已经成功地预测了疾病进展、花卉种类和图像中的物体。然而，我们仍然缺少机器学习难题中的一个重要部分：部署、维护和扩展。

如果我们的模型仅仅停留在我们的笔记本电脑上，它们就不会在公司内做任何好事或创造价值。我们需要知道如何利用我们的机器学习工作流并将其集成到我们组织中已经部署的系统中，我们需要知道如何随着时间的推移扩展、更新和维护这些工作流。

我们的机器学习工作流本质上是多阶段工作流，这一事实可能会使此部署和维护有点困难。我们需要训练、测试和利用我们的模型，在某些情况下，我们需要对数据进行预处理和/或后处理。我们可能还需要将某些模型链接在一起。我们如何部署和连接所有这些阶段，同时保持应用程序的简单性和完整性？例如，我们如何随着时间的推移更新训练数据集，同时仍然知道哪个训练数据集生成了哪些模型，哪些模型生成了哪些结果？随着对这些预测的需求不断上升和下降，我们如何能够轻松地调整我们的预测？最后，我们如何将机器学习工作流与基础设施中的其他应用程序或基础设施本身（数据库、队列等）集成？

我们将在本章中解决所有这些问题。事实证明，Go 和用 Go 编写的基础设施工具为部署和管理机器学习工作流提供了一个极好的平台。我们将使用一种从下到上的完全基于 Go 的方法，并说明其中的每一部分如何帮助我们大规模地进行数据科学！

# 在远程机器上可靠地运行模型

无论您的公司使用的是内部基础设施还是云基础设施，您都需要在某个时候在笔记本电脑以外的其他地方运行机器学习模型。这些模型可能需要为欺诈预测做好准备，或者可能需要实时处理用户上传的图像。您不能将模型放在笔记本电脑上并成功提供此信息。

然而，当我们从笔记本电脑上获取数据处理和机器学习应用程序时，我们应确保：

1.  我们不应该仅仅为了部署和扩展而使应用程序复杂化。我们应该保持我们的应用程序简单，这将有助于我们维护它们，并随着时间的推移确保完整性。
2.  我们应该确保我们的应用程序与我们开发它们的本地机器上的应用程序一样。

如果我们部署我们的机器学习工作流，而它们没有像开发过程中那样执行或行为，它们将无法产生预期的价值。我们应该能够理解我们的模型将如何在本地执行，并假设它们在生产中以相同的方式执行。由于在部署过程中给应用程序增加了不必要的复杂性，这一点越来越难以实现。

保持部署简单、可移植和可复制的一种方法是使用 Docker（[https://www.docker.com/](https://www.docker.com/) ），我们将利用它部署我们的机器学习应用程序。

Docker 本身就是用 Go 编写的，这使它成为我们将在机器学习部署堆栈中使用的第一个基于 Go 的基础设施工具。

# Docker 及 Docker 术语简介

Docker 和整个容器生态系统都有自己的一套行话，这些行话可能会让人困惑，特别是对于那些在虚拟机等方面有经验的人来说。在我们继续之前，让我们将这些术语固化如下：

*   **Docker 映像**是一组数据层的集合，这些数据层共同定义了文件系统、库、环境变量等，在软件容器中运行的应用程序可以看到这些数据层。将映像视为包含应用程序、其他相关库或包以及应用程序需要运行的环境的其他部分的包。Docker 映像不包括完整的操作系统。
*   **Docker 文件**是一个文件，您可以在其中定义 Docker 图像的各个层。
*   **Docker 引擎**帮助您构建、管理和运行 Docker 映像。
*   为应用程序构建 Docker 映像的过程通常被称为**Docker izing**应用程序。
*   **容器**或**软件容器**是 Docker 映像的运行实例。从本质上说，这个正在运行的容器包括 Docker 映像的所有层，以及允许应用程序运行、输入/输出数据等的读/写层。
*   **Docker 注册表**是保存 Docker 图像的地方。此注册表可以是本地的，也可以在远程计算机上运行。它也可以是托管的注册服务，如**Docker Hub**或 Quay、**Amazon Web service**（**AWS**）、**Amazon EC2 容器注册**（**ECR**等。

**Note**: A Docker image is not the same as a virtual machine. A Docker image includes your application, a filesystem, and various libraries and packages, but it does not actually include a guest operation system. Moreover, it does not take up a set amount of memory, disk, and CPU on the host machine when running. Docker containers share the resources of the underlying kernel on which the Docker engine is running.

我们希望所有这些行话都能在本节后面的示例中得到巩固，但与本书中的其他主题一样，您可以深入了解 Docker 和软件容器。我们将在本章的参考资料中包含一些链接，以了解更多 Docker 资源。

在以下示例中，我们假设您能够在本地构建和运行 Docker 映像。要安装 Docker，您可以按照[中的详细说明进行操作 https://www.docker.com/community-edition#/download](https://www.docker.com/community-edition#/download) 。

# Docker 正在开发一个机器学习应用程序

我们将在本章中部署和扩展的机器学习工作流将是我们在[第 4 章](04.html#2F4UM0-a5604e9f48ea4e63828d369cca8f0939)、*回归*中开发的预测糖尿病疾病进展的线性回归工作流。在我们的部署中，我们将考虑工作流的三个不同部分：

*   单一回归模型的训练和输出（用体重指数模拟疾病进展）
*   多元回归模型的训练和输出（用体重指数和血液测量 LTG 模拟疾病进展）
*   基于其中一个训练模型和输入属性的疾病进展推断

在本章的后面，我们将很清楚为什么要将工作流分成这些部分。现在，让我们把重点放在将这些工作流程片段化（即构建能够运行我们工作流程的这些部分的 Docker 映像）。

# Docker 模型培训和导出

我们将使用与[第 4 章](04.html#2F4UM0-a5604e9f48ea4e63828d369cca8f0939)、*回归*基本相同的模型训练代码。然而，我们将对代码进行一些调整，以使其更加用户友好，并能够与工作流的其他部分交互。我们不会考虑这些并发症的实际建模代码。更确切地说，这些是您可能会对任何准备更广泛地使用的应用程序执行的操作。

首先，我们将向应用程序添加一些命令行标志，这将允许我们指定训练数据集所在的输入目录，以及导出模型持久化表示的输出目录。可以按如下方式实现这些命令行参数：

```go
// Declare the input and output directory flags.
inDirPtr := flag.String("inDir", "", "The directory containing the training data")
outDirPtr := flag.String("outDir", "", "The output directory")

// Parse the command line flags.
flag.Parse()
```

然后，我们将创建两个结构类型，允许我们将模型的系数和截取导出到 JSON 文件。导出的 JSON 文件本质上是经过训练的模型的持久化版本，因为系数和截距完全参数化了我们的模型。这些结构定义如下：

```go
// ModelInfo includes the information about the
// model that is output from the training.
type ModelInfo struct {
    Intercept float64 `json:"intercept"`
    Coefficients []CoefficientInfo `json:"coefficients"`
}

// CoefficientInfo include information about a
// particular model coefficient.
type CoefficientInfo struct {
    Name string `json:"name"`
    Coefficient float64 `json:"coefficient"`
}
```

除此之外，我们的培训代码与[第 4 章](04.html#2F4UM0-a5604e9f48ea4e63828d369cca8f0939)、*回归*中的培训代码相同。我们仍将使用`github.com/sajari/regression`来训练我们的模型。我们只将模型导出到 JSON 文件。单一回归模型的培训和导出包含在以下代码段中：

```go
// Train/fit the single regression model
// with github.com/sajari/regression
// like in Chapter 5, Regression.

// Fill in the model information.
modelInfo := ModelInfo{
    Intercept: r.Coeff(0),
    Coefficients: []CoefficientInfo{
        CoefficientInfo{
            Name: "bmi",
            Coefficient: r.Coeff(1),
        },
    },
}

// Marshal the model information.
outputData, err := json.MarshalIndent(modelInfo, "", " ")
if err != nil {
    log.Fatal(err)
}

// Save the marshalled output to a file, with
// certain permissions (http://permissions-calculator.org/decode/0644/).
if err := ioutil.WriteFile(filepath.Join(*outDirPtr, "model.json"), outputData, 0644); err != nil {e model to the JSON fil
    log.Fatal(err)
}
```

然后，对于多元回归模型，过程如下所示：

```go
// Train/fit the multiple regression model
// with github.com/sajari/regression
// like in Chapter 5, Regression.

// Fill in the model information.
modelInfo := ModelInfo{
    Intercept: r.Coeff(0),
    Coefficients: []CoefficientInfo{
        CoefficientInfo{
            Name:        "bmi",
            Coefficient: r.Coeff(1),
        },
        CoefficientInfo{
            Name:        "ltg",
            Coefficient: r.Coeff(2),
        },
    },
}

// Marshal the model information.
outputData, err := json.MarshalIndent(modelInfo, "", "    ")
if err != nil {
    log.Fatal(err)
}

// Save the marshalled output to a file.
if err := ioutil.WriteFile(filepath.Join(*outDirPtr, "model.json"), outputData, 0644); err != nil {
    log.Fatal(err)
}
```

为了使这些培训过程更加贴近实际，我们需要为每个单一回归培训计划和多元回归培训计划创建一个 Dockerfile。然而，事实证明，我们可以对这些文件中的每一个使用基本相同的 Dockerfile。此 Dockerfile 应与我们的程序放在同一目录中，如下所示：

```go
FROM alpine
ADD goregtrain / 
```

很简单，对吧？让我们探讨一下这两行的目的。还记得 Docker 映像是如何由一系列层组成的吗？这些层指定了应用程序将在其中运行的环境？这个 Dockerfile 使用两个 Dockerfile 命令`FROM`和`ADD`构建了其中的两个层。

`FROM alpine`指定我们希望 Docker 映像文件系统、应用程序和库基于 Docker Hub 上提供的官方 Alpine Linux Docker 映像。我们使用`alpine`作为基本映像的原因是，它是一个非常小的 Docker 映像（使其非常可移植），并且包含一些 Linux shell 细节。

`ADD goregtrain /`指定我们要在 Docker 映像的`/`目录中添加一个`goregtrain`文件。这个`goregtrain`文件实际上是我们将从 Go 代码构建的 Go 二进制文件。因此，Dockerfile 所说的是，我们希望在 Alpine Linux 中运行 Go 二进制文件。

除非您使用的是`cgo`并且依赖于大量外部 C 库，否则在构建 Docker 映像之前，请始终构建 Go 二进制文件，并将此静态链接的 Go 二进制文件复制到 Docker 映像中。这将加快 Docker 构建的速度，并使 Docker 映像非常小，这意味着您将能够轻松地将它们移植到任何系统，并快速启动它们。

现在，我们需要在构建 Docker 映像之前构建 Go 二进制文件，因为我们正在将 Go 二进制文件复制到映像中。为此，我们将使用如下所示的`Makefile`：

```go
all: compile docker push clean

compile:
        GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -o goregtrain

docker:
        sudo docker build --force-rm=true -t dwhitena/goregtrain:single .

push:
        sudo docker push dwhitena/goregtrain:single

clean:
        rm goregtrain
```

如你所见：

*   `make compile`将为目标架构编译我们的 Go 二进制文件，并将其命名为`goregtrain`。
*   `make docker`将使用 Docker 引擎（通过`docker`CLI）基于我们的 Dockerfile 构建一个映像，并将**标记**我们的映像`dwhitena/goregtrain:single`。
*   标记的`dwhitena`部分指定我们将在其中存储图像的 Docker Hub 用户名（在本例中为`dwhitena`），`goregtrain`指定图像的名称，`:single`指定此图像的标记版本。
*   一旦建立映像，`make push`将把新建立的 Docker 映像推送到注册表。在这种情况下，它将以`dwhitena`的用户名将其推送到 Docker Hub（当然，您可以推送到任何其他私有或公共注册表）。
*   最后，`make clean`将清理二进制文件。

如上所述，`Dockerfile`和`Makefile`对于单回归模型和多元回归模型都是相同的。但是，我们将使用不同的 Docker 图像标记来区分这两种模型。我们将使用`dwhitena/goregtrain:single`作为单回归模型，使用`dwhitena/goregtrain:multi`作为多元回归模型。

在这些示例和本章的其余部分中，您可以在 Docker Hub 上使用`dwhitena`下的公共 Docker 图像进行本地跟踪，这不需要您修改此处打印的示例。请注意，您将无法在 Docker Hub 上构建自己的映像并将其推送到`dwhitena`，因为您不是`dwhitena`。或者，您可以使用自己的 Docker Hub 用户名替换示例中的[T3]。这将允许您构建、推送和利用自己的图像。

要在为单个或多个回归模型构建 Docker 映像之后构建、推送和清理，我们只需运行`make`，如下代码所示，该代码本身是用 Go 编写的：

```go
$ make
GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -o goregtrain
sudo docker build --force-rm=true -t dwhitena/goregtrain:multi .
[sudo] password for dwhitena: 
Sending build context to Docker daemon 2.449MB
Step 1/2 : FROM alpine
 ---> 7328f6f8b418
Step 2/2 : ADD goregtrain /
 ---> 9c13594ad7de
Removing intermediate container 6e717232c6d1
Successfully built 9c13594ad7de
Successfully tagged dwhitena/goregtrain:multi
sudo docker push dwhitena/goregtrain:multi
The push refers to a repository [docker.io/dwhitena/goregtrain]
375642156c06: Pushed 
5bef08742407: Layer already exists 
multi: digest: sha256:f35277a46ed840922a0d7e94c3c57632fc947f6ab004deed66d3eb80a331e40f size: 738
rm goregtrain
```

您可以在前面的输出中看到，Docker 引擎构建了图像的两层，标记了图像，并将图像推送到 Docker Hub。现在，我们可以通过以下方式在本地注册表中查看 Docker 映像：

```go
$ sudo docker images | grep "goregtrain"
dwhitena/goregtrain multi 9c13594ad7de About a minute ago 6.41MB
```

我们也可以在 Docker Hub（[上看到 https://hub.docker.com/r/dwhitena/goregtrain/](https://hub.docker.com/r/dwhitena/goregtrain/) ）如图所示：

![](img/00078.jpeg)

我们将很快看到如何运行和利用这个 Docker 映像，但是让我们首先构建另一个 Docker 映像，它将基于 JSON 持久化模型生成预测。

# Docker 模型预测

与模型的训练一样，我们将利用命令行参数指定预测程序使用的输入目录和输出目录。这次我们将有两个输入目录；一个用于持久化模型，另一个用于包含我们要从中进行预测的属性的目录。因此，我们的计划将执行以下操作：

1.  从模型输入目录中读入模型。

2.  浏览属性输入目录中的文件。
3.  对于 attributes input 目录中的每个文件（包含没有相应疾病进展预测的属性），利用我们加载的模型预测疾病进展。
4.  将疾病进展输出到指定为命令行参数的目录中的输出文件。

将这个过程想象如下。我们已经根据历史数据训练了我们的模型，以预测疾病进展，我们希望医生或诊所以某种方式为新患者利用这一预测。他们向我们发送患者属性（**体重指数**（**BMI**）或体重指数和**长期增长**（**LTG**）并根据这些输入属性进行预测。

我们将假设输入属性以 JSON 文件的形式出现在我们的程序中（也可以将其视为来自队列的 JSON 消息或 JSON API 响应），如下所示：

```go
{
  "independent_variables": [
    {
      "name": "bmi",
      "value": 0.0616962065187
    },
    {
      "name": "ltg",
      "value": 0.0199084208763
    }
  ]
}
```

因此，让我们在预测程序中创建以下结构类型，以解码输入属性并封送输出预测：

```go
// PredictionData includes the data necessary to make
// a prediction and encodes the output prediction.
type PredictionData struct {
    Prediction float64 `json:"predicted_diabetes_progression"`
    IndependentVars []IndependentVar `json:"independent_variables"`
}

// IndependentVar include information about and a
// value for an independent variable.
type IndependentVar struct {
    Name string `json:"name"`
    Value float64 `json:"value"`
}
```

我们还要创建一个函数，该函数允许我们根据从模型输入目录（即我们的持久化模型）读取的`ModelInfo`值进行预测。此`prediction`功能如下代码所示：

```go
// Predict makes a prediction based on input JSON.
func Predict(modelInfo *ModelInfo, predictionData *PredictionData) error {

    // Initialize the prediction value
    // to the intercept.
    prediction := modelInfo.Intercept

    // Create a map of independent variable coefficients.
    coeffs := make(map[string]float64)
    varNames := make([]string, len(modelInfo.Coefficients))
    for idx, coeff := range modelInfo.Coefficients {
        coeffs[coeff.Name] = coeff.Coefficient
        varNames[idx] = coeff.Name
    }

    // Create a map of the independent variable values.
    varVals := make(map[string]float64)
    for _, indVar := range predictionData.IndependentVars {
        varVals[indVar.Name] = indVar.Value
    }

    // Loop over the independent variables.
    for _, varName := range varNames {

        // Get the coefficient.
        coeff, ok := coeffs[varName]
        if !ok {
            return fmt.Errorf("Could not find model coefficient %s", varName)
        }

        // Get the variable value.
        val, ok := varVals[varName]
        if !ok {
            return fmt.Errorf("Expected a value for variable %s", varName)
        }

        // Add to the prediction.
        prediction = prediction + coeff*val
    }

    // Add the prediction to the prediction data.
    predictionData.Prediction = prediction

    return nil
}
```

这个预测函数以及类型将允许我们遍历指定输入目录中的任何属性 JSON 文件，并为每个文件输出疾病预测。此过程在以下代码中实现：

```go
// Declare the input and output directory flags.
inModelDirPtr := flag.String("inModelDir", "", "The directory containing the model.")        
inVarDirPtr := flag.String("inVarDir", "", "The directory containing the input attributes.")
outDirPtr := flag.String("outDir", "", "The output directory")

// Parse the command line flags.
flag.Parse()

// Load the model file.
f, err := ioutil.ReadFile(filepath.Join(*inModelDirPtr, "model.json"))
if err != nil {
    log.Fatal(err)
}

// Unmarshal the model information.
var modelInfo ModelInfo
if err := json.Unmarshal(f, &modelInfo); err != nil {
    log.Fatal(err)
}

// Walk over files in the input.
if err := filepath.Walk(*inVarDirPtr, func(path string, info os.FileInfo, err error) error {

    // Skip any directories.
    if info.IsDir() {
        return nil
    }

    // Open any files.
    f, err := ioutil.ReadFile(filepath.Join(*inVarDirPtr, info.Name()))
    if err != nil {
        return err
    }

    // Unmarshal the independent variables.
    var predictionData PredictionData
    if err := json.Unmarshal(f, &predictionData); err != nil {
        return err
    }

    // Make the prediction.
    if err := Predict(&modelInfo, &predictionData); err != nil {
        return err
    }

    // Marshal the prediction data.
    outputData, err := json.MarshalIndent(predictionData, "", "    ")
    if err != nil {
        log.Fatal(err)
    }

    // Save the marshalled output to a file.
    if err := ioutil.WriteFile(filepath.Join(*outDirPtr, info.Name()), outputData, 0644); err != nil {
        log.Fatal(err)
    }

    return nil
}); err != nil {
    log.Fatal(err)
}
```

我们将使用前面章节中使用的相同的`Dockerfile`和`Makefile`来对接该预测程序。唯一的区别是，我们将命名 Go 二进制文件`goregpredict`，并将 Docker 图像标记为`dwhitena/goregpredict`。使用`make`构建 Docker 映像应返回与上一节中类似的输出：

```go
$ cat Makefile 
all: compile docker push clean

compile:
 GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -o goregpredict

docker:
 sudo docker build --force-rm=true -t dwhitena/goregpredict .

push:
 sudo docker push dwhitena/goregpredict

clean:
 rm goregpredict
$ cat Dockerfile 
FROM alpine
ADD goregpredict /
$ make
GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -o goregpredict
sudo docker build --force-rm=true -t dwhitena/goregpredict .
[sudo] password for dwhitena: 
Sending build context to Docker daemon 2.38MB
Step 1/2 : FROM alpine
 ---> 7328f6f8b418
Step 2/2 : ADD goregpredict /
 ---> a2d9a63f4926
Removing intermediate container c1610b425835
Successfully built a2d9a63f4926
Successfully tagged dwhitena/goregpredict:latest
sudo docker push dwhitena/goregpredict
The push refers to a repository [docker.io/dwhitena/goregpredict]
77f12cb6c6d4: Pushed 
5bef08742407: Layer already exists 
latest: digest: sha256:9a8a754c434bf2250b2f6102bb72d56fdf723f305aebcbf5bff7e5de707dd384 size: 738
3a05f65b1d1d: Layer already exists 
5bef08742407: Layer already exists 
ult: digest: sha256:153adaa9b4b9a1f2bf02466201163c60230ae85164d9d22261f455979a94aed4 size: 738
rm goregpredict
```

# 本地测试 Docker 映像

在将 Docker 化的建模过程推送到任何服务器之前，明智的做法是在本地测试它们，以确保我们看到了预期的行为。然后，一旦我们对该行为感到满意，我们就可以放心，这些 Docker 映像将在运行 Docker 的任何其他主机上完全相同地运行。这一保证使 Docker 图像的使用成为维护部署再现性的重要贡献。

假设我们的培训数据和一些输入属性文件位于以下目录中：

```go
$ ls
attributes model training
$ ls model
$ ls attributes 
1.json 2.json 3.json
$ ls training 
diabetes.csv
```

我们可以使用`docker run`命令将 Docker 映像作为软件容器在本地运行。我们还将使用`-v`标志，它允许我们在运行的容器中装载本地目录，允许我们在本地文件系统中读写文件。

首先，让我们在 Docker 容器中运行单一回归模型培训，如下所示：

```go
$ sudo docker run -v $PWD/training:/tmp/training -v $PWD/model:/tmp/model dwhitena/goregtrain:single /goregtrain -inDir=/tmp/training -outDir=/tmp/model 

Regression Formula:
Predicted = 152.13 + bmi*949.44
```

现在，如果我们查看`model`目录中的内容，我们将在`model.json`中看到新训练的模型系数和截距，这是我们在 Docker 图像中运行的程序输出的。以下代码对此进行了说明：

```go
$ ls model 
model.json
$ cat model/model.json 
{
    "intercept": 152.13348416289818,
    "coefficients": [
        {
            "name": "bmi",
            "coefficient": 949.4352603839862
        }
    ]
}
```

杰出的我们使用 Docker 容器训练模型。现在让我们利用这个模型进行预测。具体来说，让我们使用经过训练的模型运行我们的`goregpredict`Docker 图像，对`attributes`中的三个属性文件进行预测。在以下代码中，您将看到属性文件在运行 Docker 映像之前没有相应的预测，但在运行 Docker 映像之后有相应的预测：

```go
$ cat attributes/1.json
{
    "independent_variables": [
        {
            "name": "bmi",
            "value": 0.0616962065187
        },
        {
            "name": "ltg",
            "value": 0.0199084208763
        }
    ]
}
$ sudo docker run -v $PWD/attributes:/tmp/attributes -v $PWD/model:/tmp/model dwhitena/goregpredict /goregpredict -inModelDir=/tmp/model -inVarDir=/tmp/attributes -outDir=/tmp/attributes
$ cat attributes/1.json 
{
    "predicted_diabetes_progression": 210.7100380636843,
    "independent_variables": [
        {
            "name": "bmi",
            "value": 0.0616962065187
        },
        {
            "name": "ltg",
            "value": 0.0199084208763
        }
    ]
}
```

# 在远程计算机上运行 Docker 映像

你可能会想，*有什么大不了的，你可以通过 Docker 获得与我们通过构建和运行 Go 程序*相同的功能。嗯，这在本地是正确的，但是当我们想要在笔记本电脑以外的环境中运行相同的功能时，Docker 的魔力就产生了。

我们可以获取这些 Docker 映像，并在运行 Docker 的任何主机上以完全相同的方式运行它们，它们将产生完全相同的行为。这对于任何 Docker 图像都是正确的。您不必安装 Docker 映像内部可能分层的任何依赖项。你只需要 Docker。

你猜怎么着？我们的 Docker 图像大小仅为 3MB 左右！这意味着他们将以超快的速度下载到任何主机，并以超快的速度启动和运行。您不必担心拖拽多个千兆字节大小的虚拟机和手动指定资源。

# 构建可扩展且可复制的机器学习管道

Docker 为在公司基础设施中部署机器学习工作流程开辟了不少道路。但是，仍有一些缺失，如下所述：

*   我们如何将工作流的各个阶段串联在一起？在这个简单的例子中，我们有一个训练阶段和一个预测阶段。在其他管道中，还可以进行数据预处理、数据拆分、数据合并、可视化、评估等。
*   如何在工作流程的正确阶段获得正确的数据，特别是当我们收到新数据和/或数据更改时？每次我们需要进行新的预测时，手动将新属性复制到与预测图像位于同一位置的文件夹是不可持续的，并且我们无法在每次需要更新培训集时登录到服务器。
*   我们将如何跟踪和再现工作流的各种运行，以进行维护、持续开发或调试？如果我们在一段时间内进行预测，并在一段时间内更新我们的模型和/或训练集，我们需要了解哪些模型产生了哪些结果，以保持再现性（在某些情况下，为了满足合规性）。
*   我们如何在多台机器上以及在某些情况下在多个共享资源上扩展处理？我们可能需要在公司的一些共享资源集上运行我们的处理。对于我们来说，能够在这些资源上扩展我们的处理是很好的，因为我们需要更多的计算能力和/或其他应用程序被安排在这些资源上。

谢天谢地，还有一些开源工具（都是用 Go 编写的）可以为我们解决这些问题。不仅如此，他们还允许我们使用我们已经构建的 Docker 图像作为数据处理的主要单元。这些工具是**库伯内特斯**（**k8s**）和**厚皮动物**。

您已经在[第一章](01.html#KVCC0-a5604e9f48ea4e63828d369cca8f0939)*收集和整理数据*中接触过厚皮动物。在那一章中，我们使用了 Pachydrm 来说明数据版本控制的思想，正如您可能猜到的那样，Pachydrm 将帮助我们解决有关管理数据、跟踪和再现性的一些问题。Pachydrm 还将解决我们需要解决的关于可伸缩性和管道化的所有剩余问题，因为 Pachydrm 提供了数据管理/版本控制功能和数据管道化功能。

Kubernetes 是一个容器编排引擎，它在跨共享资源集群调度容器化工作负载（如 Docker 映像）方面非常出色。它现在非常流行，Pachyderm 利用引擎盖下的 Kubernetes 来管理集装箱数据处理管道。

# 建立厚皮动物群和库伯内特斯群

运行在 Kubernetes 上的 Pachyderm 几乎可以部署在任何地方，因为 Kubernetes 可以部署在任何地方。您可以在任何流行的云提供商、内部部署，甚至在您自己的笔记本电脑上部署 Pachydrm。部署 Pachydrm 群集只需执行以下操作：

1.  拥有一个正在运行的 Kubernetes 群集。
2.  可以访问您选择的对象存储（例如，S3、**格拉斯哥昏迷量表**（**GCS**）或 Minio）。此对象存储将用作存储所有版本控制和处理数据的 Pachydrm 集群的存储备份。
3.  使用 Pachydrm CLI`pachctl`在 Kubernetes 群集上部署 Pachydrm。

有关在任何云提供商或本地部署 Pachydrm 的详细说明，请参见[http://pachyderm.readthedocs.io/en/latest/deployment/deploy_intro.html](http://pachyderm.readthedocs.io/en/latest/deployment/deploy_intro.html) 。或者，您可以使用`minikube`轻松地对本地厚皮动物集群进行实验和开发，详见[http://pachyderm.readthedocs.io/en/latest/getting_started/local_installation.html](http://pachyderm.readthedocs.io/en/latest/getting_started/local_installation.html) 。

以下一组说明将使您进入 Kubernetes 群集在以下状态下运行的状态（可使用名为`kubectl`的 Kubernetes CLI 工具进行检查）：

```go
$ kubectl get all
NAME READY STATUS RESTARTS AGE
po/etcd-2142892294-38ptw 1/1 Running 0 2m
po/pachd-776177201-04l6w 1/1 Running 0 2m

NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE
svc/etcd 10.0.0.141 <nodes> 2379:32379/TCP 2m
svc/kubernetes 10.0.0.1 <none> 443/TCP 3m
svc/pachd 10.0.0.178 <nodes> 650:30650/TCP,651:30651/TCP,652:30652/TCP 2m

NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE
deploy/etcd 1 1 1 1 2m
deploy/pachd 1 1 1 1 2m

NAME DESIRED CURRENT READY AGE
rs/etcd-2142892294 1 1 1 2m
rs/pachd-776177201 1 1 1 2m
```

在这里，您可以看到 Pachyderm 守护程序（或服务器）`pachd`正在 Kubernetes 集群中作为**pod**运行，它只是一个或多个容器的组。我们的管道阶段也将作为 Kubernetes 吊舱运行，但您不必太担心，因为厚皮动物将负责细节。

上述输出中列出的端口和 IP 可能因您的部署和各种配置而异。然而，一个健康的厚皮动物集群应该看起来非常相似。

如果您的 Pachydrm 群集正在运行，并且您遵循了其中一个 Pachydrm 部署指南，那么还应该安装[T0]CLI 工具。当`pachctl`成功连接到 Pachydrm 群集时，您可以运行以下操作作为进一步的健全性检查（其中版本号可能会根据您正在运行的 Pachydrm 版本进行更改）：

```go
$ pachctl version
COMPONENT           VERSION             
pachctl             1.6.0           
pachd               1.6.0
```

如果您在部署 Pachyderm 时遇到任何问题，或者在构建或运行管道时遇到任何问题，Pachyderm 社区有一个很好的公共 Pachyderm 松弛通道。您可以通过访问[加入 http://slack.pachyderm.io/](http://slack.pachyderm.io/) 。社区每天都很活跃，欢迎你提出任何问题。

# 构建厚皮动物机器学习管道

正如您已经看到的，我们的示例机器学习管道有两个阶段。我们管道的模型阶段将训练一个模型，并将该模型的持久版本导出到一个文件中。我们管道的预测阶段将利用经过训练的模型对输入属性文件进行预测。总的来说，该管道在 Pachydrm 中的外观如下所示：

![](img/00079.jpeg)

上图中的每个圆柱体表示一个版本化数据的 Pachydrm 数据存储库。您已经在[第 1 章](01.html#KVCC0-a5604e9f48ea4e63828d369cca8f0939)*收集和组织数据*中接触到了这些数据存储库。每个框表示一个容器化数据管道阶段。厚皮动物数据处理的基本单位是 Docker 图像。因此，我们可以利用我们在此数据管道的前面部分中创建的 Docker 图像。

通过将版本化的数据集合串在一起（同样，将它们看作是一种数据的[T0]Git[T1]，使用容器处理这些数据集合，并将结果保存到其他版本化的数据集合，Pachyderm 管道具有一些非常有趣和有用的含义。

首先，我们可以在任何时间点返回，以查看在该时间点数据的任何部分的状态。如果我们想要开发数据的特定状态，这可能有助于我们进一步开发模型。随着时间的推移，它还可以帮助我们作为一个团队协作开发团队的数据。并非所有对数据的更改都是好的，我们需要在将坏数据或损坏的数据提交到系统后恢复。

接下来，我们所有的管道结果都链接到精确的 Docker 图像以及产生这些结果的其他数据的精确状态。厚皮动物研究小组称之为**起源**。它是一种理解哪些处理片段以及哪些数据片段促成了特定结果的能力。例如，通过这个管道，我们能够确定产生特定结果的持久化模型的确切版本，以及产生该模型的确切 Docker 映像和输入到该确切 Docker 映像的训练数据的确切状态。因此，我们能够准确地再现任何管道的整个运行，调试奇怪的模型行为，并将结果归因于相应的输入数据。

最后，因为 Pachydrm 知道您的数据存储库的哪些部分是新的或不同的，所以我们的数据管道可以增量处理数据，并且可以自动触发。假设我们已经将一百万个属性文件提交到`attributes`数据存储库中，然后再提交十个属性文件。我们不需要重新处理第一批一百万来更新我们的结果。Pachydrm 知道我们只需要处理十个新文件，并将这些文件发送到`prediction`阶段进行处理。此外，Pachydrm（默认情况下）将自动触发此更新，因为它知道需要更新以保持结果与输入同步。

增量处理和自动触发器是 Pachyderm 管道的一些默认行为，但它们不是使用 Pachyderm 可以做的唯一事情。事实上，我们在这里只讨论厚皮动物可能发生的情况。您可以执行分布式 map/reduce 样式的操作、分布式图像处理、定期处理数据库表，等等。因此，这里的技术应该可以转移到各种领域。

# 创建和填充输入存储库

要在已部署的 Pachydrm 集群上创建 Pachydrm 管道，首先需要为管道创建输入存储库。记住，我们的管道有`training`和`attributes`数据存储库，它们驱动管道的其余部分。当我们将数据输入这些数据时，Pachydrm 将触发管道的下游部分并计算结果。

我们在[第 1 章](01.html#KVCC0-a5604e9f48ea4e63828d369cca8f0939)*收集和组织数据*中看到，我们如何在 Pachydrm 中创建数据存储库，并使用`pachctl`将数据提交到这些存储库中，但让我们尝试直接从 Go 程序中实现这一点。在这个特定的示例中，这样做没有任何真正的好处，因为我们已经将培训和测试数据保存在文件中，并且我们可以很容易地按名称将这些文件提交到 Pachydrm 中。

然而，想象一个更现实的场景。我们可能希望我们的数据管道与我们公司已经编写的其他 Go 服务集成。其中一项服务可能会处理来自医生或诊所的传入患者医疗属性，我们希望将这些属性提供给我们的数据管道，以便数据管道能够对疾病进展做出相应的预测。

在这种情况下，理想情况下，我们希望将属性从我们的服务直接传递到 Pachydrm，而不是手动复制所有这些数据。这就是 Pachyderm Go 客户端`github.com/pachyderm/pachyderm/src/client`非常方便的地方。使用 Pachydrm Go 客户端，我们可以按如下方式创建输入存储库（连接到 Pachydrm 集群后）：

```go
// Connect to Pachyderm using the IP of our
// Kubernetes cluster. Here we will use localhost
// to mimic the scenario when you have k8s running
// locally and/or you are forwarding the Pachyderm
// port to your localhost.. By default
// Pachyderm will be exposed on port 30650.
c, err := client.NewFromAddress("0.0.0.0:30650")
if err != nil {
    log.Fatal(err)
}
defer c.Close()

// Create a data repository called "training."
if err := c.CreateRepo("training"); err != nil {
    log.Fatal(err)
}

// Create a data repository called "attributes."
if err := c.CreateRepo("attributes"); err != nil {
    log.Fatal(err)
}

// Now, we will list all the current data repositories
// on the Pachyderm cluster as a sanity check. We
// should now have two data repositories.
repos, err := c.ListRepo(nil)
if err != nil {
    log.Fatal(err)
}

// Check that the number of repos is what we expect.
if len(repos) != 2 {
    log.Fatal("Unexpected number of data repositories")
}

// Check that the name of the repo is what we expect.
if repos[0].Repo.Name != "attributes" || repos[1].Repo.Name != "training" {
    log.Fatal("Unexpected data repository name")
}
```

编译并运行它会按预期创建`repos`，可以确认如下：

```go
$ go build
$ ./myprogram
$ pachctl list-repo
NAME CREATED SIZE 
attributes 3 seconds ago 0B 
training 3 seconds ago 0B 
```

为了简单起见，上面的代码只创建和检查一次回购协议。如果再次运行代码，则会出现错误，因为已经创建了回购协议。为了改进这一点，您可以检查回购协议是否存在，如果不存在，则创建它。您还可以按名称检查回购是否存在。

现在，让我们继续将属性文件放入`attributes`存储库，将`diabetes.csv`训练数据集放入`training`存储库。这也很容易通过 Pachydrm 客户端直接在 Go 中完成：

```go
// Connect to Pachyderm.
c, err := client.NewFromAddress("0.0.0.0:30650")
if err != nil {
    log.Fatal(err)
}
defer c.Close()

// Start a commit in our "attributes" data repo on the "master" branch.
commit, err := c.StartCommit("attributes", "master")
if err != nil {
    log.Fatal(err)
}

// Open one of the attributes JSON files.
f, err := os.Open("1.json")
if err != nil {
    log.Fatal(err)
}

// Put a file containing the attributes into the data repository.
if _, err := c.PutFile("attributes", commit.ID, "1.json", f); err != nil {
    log.Fatal(err)
}

// Finish the commit.
if err := c.FinishCommit("attributes", commit.ID); err != nil {
    log.Fatal(err)
}

// Start a commit in our "training" data repo on the "master" branch.
commit, err = c.StartCommit("training", "master")
if err != nil {
    log.Fatal(err)
}

// Open up the training data set.
f, err = os.Open("diabetes.csv")
if err != nil {
    log.Fatal(err)
}

// Put a file containing the training data set into the data repository.
if _, err := c.PutFile("training", commit.ID, "diabetes.csv", f); err != nil {
    log.Fatal(err)
}

// Finish the commit.
if err := c.FinishCommit("training", commit.ID); err != nil {
    log.Fatal(err)
}
```

运行此操作确实会将数据提交到适当的数据存储库中的 Pachydrm 中，如下所示：

```go
$ go build
$ ./myprogram 
$ pachctl list-repo
NAME CREATED SIZE 
training 13 minutes ago 73.74KiB 
attributes 13 minutes ago 210B 
$ pachctl list-file training master
NAME TYPE SIZE 
diabetes.csv file 73.74KiB 
$ pachctl list-file attributes master
NAME TYPE SIZE 
1.json file 210B
```

完成上面开始的提交是很重要的。如果将孤立的提交挂起，则可能会阻止其他数据提交。因此，您可能会考虑推迟提交的完成，只是为了安全。

好的现在，我们在远程 Pachydrm 集群上的适当输入数据存储库中有了数据。接下来，我们可以实际处理这些数据并产生结果。

# 创建和运行处理阶段

处理阶段通过 Pachydrm 中的**管道规范**以声明方式创建。如果您以前使用过 Kubernetes，那么这种类型的交互应该很熟悉。基本上，我们向 Pachydrm 声明我们希望进行的处理，并且 Pachydrm 处理所有细节以确保该处理按照声明的方式进行。

让我们首先使用存储在`train.json`中的 JSON 管道规范创建管道的`model`阶段。此 JSON 规范如下所示：

```go
{
  "pipeline": {
    "name": "model"
  },
  "transform": {
    "image": "dwhitena/goregtrain:single",
    "cmd": [ 
      "/goregtrain",
      "-inDir=/pfs/training",
      "-outDir=/pfs/out"
    ] 
  },
  "parallelism_spec": {
    "constant": "1"
  },
  "input": {
    "atom": {
      "repo": "training",
      "glob": "/"
    }
  }
}
```

这看起来可能有点复杂，但实际上这里只发生了一些事情。让我们仔细分析规范，了解不同的部分：

1.  首先，我们告诉 Pachydrm 命名我们的管道`model`。

2.  接下来，我们告诉 Pachydrm，我们希望这个`model`管道使用我们的`dwhitena/goregtrain:single`处理数据，我们希望管道在处理数据时在容器中运行我们的`goregtrain`二进制文件。
3.  最后，规范告诉 Pachydrm 我们打算将`training`数据存储库作为输入进行处理。

为了理解该规范的其他一些细节，我们需要首先讨论使用该规范在我们的 Pachydrm 集群上创建管道时会发生什么。当这种情况发生时，Pachyderm 将使用 Kubernetes 在 Kubernetes 集群上调度一个或多个 worker 吊舱。然后，这些工作者吊舱将等待，准备处理 Pachydrm 守护进程提供给它们的任何数据。当输入存储库`training`中存在需要处理的数据时，Pachydrm 守护进程将触发一个作业，这些工作人员将在其中处理数据。Pachydrm 将自动将输入数据装载到位于`/pfs/<input repo name>`（本例中为`/pfs/training`的容器中）。容器写入`/pfs/out`的数据将在输出数据存储库中自动进行版本控制，该存储库与管道同名（本例中为`model`。

规范的`parallelism_spec`部分让我们告诉 Pachydrm 它应该启动多少工人来处理输入数据。在这里，我们将只启动一个 worker 并串行处理数据。在本章后面，我们将讨论并行化我们的管道和相关的数据分片，它由规范的`input`部分中的`glob`模式控制。

说够了！让我们在我们的厚皮动物集群上创建这个`model`管道阶段，开始处理一些数据。可以按如下方式轻松创建管道：

```go
$ pachctl create-pipeline -f model.json
```

当我们这样做时，我们可以看到 Pachydrm 使用`kubectl`在 Kubernetes 集群上创建的 worker，如下代码所示：

```go
$ kubectl get pods
NAME READY STATUS RESTARTS AGE
etcd-2142892294-38ptw 1/1 Running 0 2h
pachd-776177201-04l6w 1/1 Running 0 2h
pipeline-model-v1-p0lnf 2/2 Running 0 1m
```

我们还将看到，厚皮动物已经自动触发一个作业来执行我们的模型训练。请记住，之所以会发生这种情况，是因为 Pachyderm 知道输入存储库[T0]中存在尚未处理的数据。您可以看到触发的作业及其结果，如下所示：

```go
$ pachctl list-job
ID OUTPUT COMMIT STARTED DURATION RESTART PROGRESS DL UL STATE 
14f052ae-878d-44c9-a1f9-ab0cf6d45227 model/a2c7b7dfb44a40e79318c2de30c7a0c8 3 minutes ago Less than a second 0 1 + 0 / 1 73.74KiB 160B success 
$ pachctl list-repo
NAME CREATED SIZE 
model 3 minutes ago 160B 
training About an hour ago 73.74KiB 
attributes About an hour ago 210B 
$ pachctl list-file model master
NAME TYPE SIZE k8s
model.json file 160B 
$ pachctl get-file model master model.json
{
    "intercept": 152.13348416289818,
    "coefficients": [
        {
            "name": "bmi",
            "coefficient": 949.4352603839862
        }
    ]
}
```

伟大的我们可以看到，我们的模型培训产生了我们预期的结果。然而，Pachyderm 足够聪明，可以触发管道，并且每当我们修改训练数据集时，它都会更新此模型。

[T0]管道可以以类似的方式创建。其管道规格`pipeline.json`如图所示：

```go
{
  "pipeline": {
    "name": "prediction"
  },
  "transform": {
    "image": "dwhitena/goregpredict",
    "cmd": [ 
      "/goregpredict", 
      "-inModelDir=/pfs/model", 
      "-inVarDir=/pfs/attributes", 
      "-outDir=/pfs/out" 
    ]
  },
  "parallelism_spec": {
    "constant": "1"
  },
  "input": {
    "cross": [
      {
        "atom": {
          "repo": "attributes",
          "glob": "/*"
        }
      },
      {
        "atom": {
          "repo": "model",
          "glob": "/"
        }
      }
    ]
  }
}
```

这个管道规范的主要区别在于我们有两个输入存储库而不是一个。这两个输入存储库是我们之前创建的`attributes`存储库和包含`model`管道输出的`model`存储库。使用`cross`原语组合这些元素。`cross`确保处理我们的模型和属性文件的所有相关对。

如果您感兴趣，您可以在 Pachydrm 文档中找到更多有关合并 Pachydrm 中数据的其他方法；转到[http://pachyderm.readthedocs.io/en/latest/](http://pachyderm.readthedocs.io/en/latest/) 。

创建此管道并检查结果（对应于`1.json`）可按如下方式完成：

```go
$ pachctl create-pipeline -f prediction.json 
$ pachctl list-job
ID OUTPUT COMMIT STARTED DURATION RESTART PROGRESS DL UL STATE 
03f36398-89db-4de4-ad3d-7346d56883c0 prediction/5ce47c9e788d4893ae00c7ee6b1e8431 About a minute ago Less than a second 0 1 + 0 / 1 370B 266B success 
14f052ae-878d-44c9-a1f9-ab0cf6d45227 model/a2c7b7dfb44a40e79318c2de30c7a0c8 19 minutes ago Less than a second 0 1 + 0 / 1 73.74KiB 160B success 
$ pachctl list-repo
NAME CREATED SIZE 
prediction About a minute ago 266B 
model 19 minutes ago 160B 
training About an hour ago 73.74KiB 
attributes About an hour ago 210B 
$ pachctl list-file prediction master
NAME TYPE SIZE 
1.json file 266B 
$ pachctl get-file prediction master 1.json
{
    "predicted_diabetes_progression": 210.7100380636843,
    "independent_variables": [
        {
            "name": "bmi",
            "value": 0.0616962065187
        },
        {
            "name": "ltg",
            "value": 0.0199084208763
        }
    ]
}
```

您可以看到，创建了另一个数据存储库`prediction`，以对`prediction`管道的输出进行版本化。通过这种方式，Pachyderm 逐渐在输入数据存储库、数据处理阶段和输出数据存储库之间建立链接，以便它始终知道链接了哪些数据和处理组件。

现在已经部署了完整的机器学习管道，我们已经运行了管道的每个阶段一次。但是，管道已准备就绪，正在等待处理更多数据。我们所要做的就是将数据放在管道的顶端，Pachydrm 将自动触发任何需要进行的下游处理，以更新我们的结果。让我们通过将另外两个文件提交到`attributes`存储库来说明这一点，如下所示：

```go
$ ls
2.json 3.json
$ pachctl put-file attributes master -c -r -f .
$ pachctl list-file attributes master
NAME TYPE SIZE 
1.json file 210B 
2.json file 211B 
3.json file 211B
```

这将自动触发另一个预测作业来更新我们的结果。新作业可以在以下代码中看到：

```go
$ pachctl list-job
ID OUTPUT COMMIT STARTED DURATION RESTART PROGRESS DL UL STATE 
be71b034-9333-4f75-b443-98d7bc5b48ab prediction/bb2fd223df664e70ad14b14491109c0f About a minute ago Less than a second 0 2 + 1 / 3 742B 536B success 
03f36398-89db-4de4-ad3d-7346d56883c0 prediction/5ce47c9e788d4893ae00c7ee6b1e8431 8 minutes ago Less than a second 0 1 + 0 / 1 370B 266B success 
14f052ae-878d-44c9-a1f9-ab0cf6d45227 model/a2c7b7dfb44a40e79318c2de30c7a0c8 26 minutes ago Less than a second 0 1 + 0 / 1 73.74KiB 160B success
```

此外，我们还可以看到，`prediction`存储库在两个新输入文件上再次运行我们的预测代码得到了两个新结果：

```go
$ pachctl list-file prediction master
NAME TYPE SIZE 
1.json file 266B 
2.json file 268B 
3.json file 268B
```

请注意，尽管显示了最新的结果，但厚皮动物并未在此处重新处理`1.json`。在引擎盖下，厚皮动物知道在`attributes`中已经有一个对应于`1.json`的结果，所以不需要再处理。

# 更新管道和检查出处

随着时间的推移，我们可能会想要更新我们的机器学习模型。他们正在处理的数据可能随着时间的推移而改变，或者我们刚刚开发了一个不同或更好的模型。无论如何，我们可能需要更新我们的管道。

让我们假设我们的管道处于上一节中描述的状态，在这里我们已经创建了完整的管道，培训过程已经运行了一次，并且我们已经将两个提交处理到`attributes`存储库中。现在，让我们更新模型管道来训练我们的多元回归

现在，让我们更新模型管道来训练多元回归模型，而不是单一回归模型。这其实很容易。我们只需将`model.json`管线规格中的`"image": "dwhitena/goregtrain:single"`改为`"image": "dwhitena/goregtrain:multi"`，然后更新管线如下：

```go
$ pachctl update-pipeline -f model.json --reprocess
```

当我们给 Pachydrm 这个新的规范时，Pachydrm 将自动更新 worker pod，以便它们使用多元回归模型运行容器。此外，由于我们提供了`--reprocess`标志，Pachyderm 将触发一个或多个新作业，以重新处理以前使用旧图像处理的新图像的任何输入提交。我们可以看到这些再加工作业如下：

```go
$ pachctl list-job
ID OUTPUT COMMIT STARTED DURATION RESTART PROGRESS DL UL STATE 
03667301-980b-484b-afbe-7ea30da695f5 prediction/ef32a74b04ee4edda7bc2a2b469f3e03 2 minutes ago Less than a second 0 3 + 0 / 3 1.355KiB 803B success 
5587e13c-4854-4f3a-bc4c-ae88c65c007f model/f54ca1a0142542579c1543e41f5e9403 2 minutes ago Less than a second 0 1 + 0 / 1 73.74KiB 252B success 
be71b034-9333-4f75-b443-98d7bc5b48ab prediction/bb2fd223df664e70ad14b14491109c0f 16 minutes ago Less than a second 0 2 + 1 / 3 742B 536B success 
03f36398-89db-4de4-ad3d-7346d56883c0 prediction/5ce47c9e788d4893ae00c7ee6b1e8431 23 minutes ago Less than a second 0 1 + 0 / 1 370B 266B success 
14f052ae-878d-44c9-a1f9-ab0cf6d45227 model/a2c7b7dfb44a40e79318c2de30c7a0c8 41 minutes ago Less than a second 0 1 + 0 / 1 73.74KiB 160B success
```

看看这个输出，我们可以注意到一些有趣且非常有用的东西。当我们的`model`阶段训练我们的新多元回归模型并将该模型输出为`model.json`时，Pachyderm 发现我们的`prediction`管道的结果现在与最新模型不同步。因此，Pachyderm 自动触发另一个作业，使用新的多元回归模型更新我们以前的结果。

此工作流对于管理已部署的模型以及在模型开发过程中非常有用，因为您不需要手动调整模型版本和相关数据。一切都是自动发生的。然而，这一更新自然产生了一个问题。我们如何知道哪些模型产生了哪些结果？

好的，这就是 Pachydrm 的数据版本控制和流水线技术结合起来的地方。我们可以查看任何预测结果并检查该提交以确定提交的来源。这一点如下所示：

```go
$ pachctl inspect-commit prediction ef32a74b04ee4edda7bc2a2b469f3e03
Commit: prediction/ef32a74b04ee4edda7bc2a2b469f3e03
Parent: bb2fd223df664e70ad14b14491109c0f 
Started: 8 minutes ago
Finished: 8 minutes ago 
Size: 803B
Provenance: training/e0f9357455234d8bb68540af1e8dde81 attributes/2e5fef211f14498ab34c0520727296bb model/f54ca1a0142542579c1543e41f5e9403
```

在这种情况下，我们可以看到预测`ef32a74b04ee4edda7bc2a2b469f3e03`是由模型`f54ca1a0142542579c1543e41f5e9403`产生的，可以在这里检索到：

```go
$ pachctl get-file model f54ca1a0142542579c1543e41f5e9403 model.json
{
    "intercept": 152.13348416289583,
    "coefficients": [
        {
            "name": "bmi",
            "coefficient": 675.069774431606
        },
        {
            "name": "ltg",
            "coefficient": 614.9505047824742
        }
    ]
}
```

然而，如果我们看一下之前的预测，我们会发现它是由不同的模型产生的：

```go
$ pachctl inspect-commit prediction bb2fd223df664e70ad14b14491109c0f
Commit: prediction/bb2fd223df664e70ad14b14491109c0f
Parent: 5ce47c9e788d4893ae00c7ee6b1e8431 
Started: 25 minutes ago
Finished: 25 minutes ago 
Size: 802B
Provenance: model/a2c7b7dfb44a40e79318c2de30c7a0c8 training/e0f9357455234d8bb68540af1e8dde81 attributes/2e5fef211f14498ab34c0520727296bb 
$ pachctl get-file model a2c7b7dfb44a40e79318c2de30c7a0c8 model.json
{
    "intercept": 152.13348416289818,
    "coefficients": [
        {
            "name": "bmi",
            "coefficient": 949.4352603839862
        }
    ]
}
```

无论运行了多少个作业，更新了多少次管道，我们都可以追溯管道中任何数据的来源。这对于创建可持续的机器学习工作流程非常重要，这些工作流程可以随着时间的推移进行维护、改进和更新，而不会带来重大麻烦。

# 缩放管道级

Pachydrm 中的每个管道规格可以有一个对应的`parallelism_spec`字段。该字段以及输入中的`glob`模式允许您在输入数据上并行化管道阶段。每个管道阶段都是独立于所有其他管道阶段的单独可伸缩的。

管道规范中的`parallelism_spec`字段允许您控制 Pachydrm 在该管道阶段处理数据的人数。例如，下面的`parallelism_spec`将告诉 Pachydrm 为一条管道增加 10 名工人：

```go
  "parallelism_spec": {
    "constant": "10"
  },
```

输入中的[T0]模式告诉 Pachydrm 它如何通过[T1]声明的 worker 共享您的输入数据。例如，`/*`的`glob`模式会告诉 Pachydrm，它可以将您的输入数据拆分为包含存储库根目录的任何文件的基准。`/*/*`的 glob 模式会告诉 Pachyderm，它可以将您的数据拆分为数据库，这些数据库由文件或目录组成，位于存储库目录结构的深处。如果您不熟悉 glob 模式，请使用以下示例查看此说明：[https://en.wikipedia.org/wiki/Glob_（编程）](https://en.wikipedia.org/wiki/Glob_(programming))。

在我们的示例管道中，我们可以想象我们需要扩展管道的`prediction`阶段，因为我们看到大量需要相应预测的属性涌入。如果是这种情况，我们可以将`prediction.json`管道规范中的`parallelism_spec`更改为`"constant": "10"`。一旦我们用新规格更新管道，Pachydrm 将为`prediction`管道增加 10 名新工人，如下所示：

```go
$ pachctl update-pipeline -f prediction.json
 $ kubectl get pods
 NAME READY STATUS RESTARTS AGE
 etcd-2142892294-38ptw 1/1 Running 0 3h
 pachd-776177201-04l6w 1/1 Running 0 3h
 pipeline-model-v2-168k5 2/2 Running 0 29m
 pipeline-prediction-v2-0p6zs 0/2 Init:0/1 0 6s
 pipeline-prediction-v2-3fbsc 0/2 Init:0/1 0 6s
 pipeline-prediction-v2-c3m4f 0/2 Init:0/1 0 6s
 pipeline-prediction-v2-d11b9 0/2 Init:0/1 0 6s
 pipeline-prediction-v2-hjdll 0/2 Init:0/1 0 6s
 pipeline-prediction-v2-hnk64 0/2 Init:0/1 0 6s
 pipeline-prediction-v2-q29f1 0/2 Init:0/1 0 6s
 pipeline-prediction-v2-qlhm4 0/2 Init:0/1 0 6s
 pipeline-prediction-v2-qrnf9 0/2 Init:0/1 0 6s
 pipeline-prediction-v2-rdt81 0/2 Init:0/1 0 6s
 $ kubectl get pods
 NAME READY STATUS RESTARTS AGE
 etcd-2142892294-38ptw 1/1 Running 0 3h
 pachd-776177201-04l6w 1/1 Running 0 3h
 pipeline-model-v2-168k5 2/2 Running 0 30m
 pipeline-prediction-v2-0p6zs 2/2 Running 0 26s
 pipeline-prediction-v2-3fbsc 2/2 Running 0 26s
 pipeline-prediction-v2-c3m4f 2/2 Running 0 26s
 pipeline-prediction-v2-d11b9 2/2 Running 0 26s
 pipeline-prediction-v2-hjdll 2/2 Running 0 26s
 pipeline-prediction-v2-hnk64 2/2 Running 0 26s
 pipeline-prediction-v2-q29f1 2/2 Running 0 26s
 pipeline-prediction-v2-qlhm4 2/2 Running 0 26s
 pipeline-prediction-v2-qrnf9 2/2 Running 0 26s
 pipeline-prediction-v2-rdt81 2/2 Running 0 26s
```

现在，任何新提交到`attributes`回购协议的属性都将由 10 名工作人员并行处理。例如，如果我们将 100 多个属性文件提交到`attributes`中，Pachydrm 会将这些文件的 1/10 发送给 10 个工作者中的每一个，以便并行处理。在`prediction`回购协议中，所有结果仍将以同样的方式出现。

当然，设置固定数量的工作者并不是使用厚皮动物和 Kubernetes 进行缩放的唯一方法。Pachydrm 还可以通过设置空闲工作人员的缩小阈值来缩小工作人员的规模。此外，工作人员的 Pachyderm 自动缩放可以与 Kubernetes 群集资源的自动缩放相结合，以处理突发数据和批处理。此外，Pachydrm 将允许您指定管道所需的资源，并且使用此资源规范，您可以将机器学习工作负载卸载到加速器（例如 GPU）。

# 工具书类

码头工人：

*   码头工人简介：[https://training.docker.com/introduction-to-docker](https://training.docker.com/introduction-to-docker)
*   为 Go 应用程序构建最小 Docker 映像：[https://blog.codeship.com/building-minimal-docker-containers-for-go-applications/](https://blog.codeship.com/building-minimal-docker-containers-for-go-applications/)

厚皮动物：

*   公共休闲频道：[http://slack.pachyderm.io/](http://slack.pachyderm.io/)
*   入门指南：[http://pachyderm.readthedocs.io/en/latest/getting_started/getting_started.html](http://pachyderm.readthedocs.io/en/latest/getting_started/getting_started.html)
*   Go 客户单据：[https://godoc.org/github.com/pachyderm/pachyderm/src/client](https://godoc.org/github.com/pachyderm/pachyderm/src/client) [﻿](https://godoc.org/github.com/pachyderm/pachyderm/src/client)
*   使用厚皮动物进行机器学习：[http://pachyderm.readthedocs.io/en/latest/cookbook/ml.html](http://pachyderm.readthedocs.io/en/latest/cookbook/ml.html)
*   机器学习示例：[http://pachyderm.readthedocs.io/en/latest/examples/readme.html#machine-学习](http://pachyderm.readthedocs.io/en/latest/examples/readme.html#machine-learning)
*   使用厚皮动物进行分布式处理：[http://pachyderm.readthedocs.io/en/latest/fundamentals/distributed_computing.html](http://pachyderm.readthedocs.io/en/latest/fundamentals/distributed_computing.html)
*   常见厚皮动物部署：[http://pachyderm.readthedocs.io/en/latest/deployment/deploy_intro.html](http://pachyderm.readthedocs.io/en/latest/deployment/deploy_intro.html)
*   自动缩放厚皮动物集群：[http://pachyderm.readthedocs.io/en/latest/managing_pachyderm/autoscaling.html](http://pachyderm.readthedocs.io/en/latest/managing_pachyderm/autoscaling.html)

# 总结

从仅仅收集 CSV 数据到完全部署的分布式机器学习管道，我们做到了！现在，我们可以使用 Go 构建机器学习模型，并在机器集群上自信地部署这些模型。这些模式应该允许您构建和部署各种各样的智能应用程序，我迫不及待地想知道您创建了什么！请保持联系。