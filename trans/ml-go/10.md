# 与机器学习相关的算法/技术

有一些算法和技术，与本书中的机器学习示例相关，在前面的章节中我们无法详细介绍。我们将在这里讨论这个问题。

# 梯度下降

在多个示例中（包括[第 4 章](04.html#2F4UM0-a5604e9f48ea4e63828d369cca8f0939)、*回归*和[第 5 章](05.html#2TEN40-a5604e9f48ea4e63828d369cca8f0939)*、分类*中的示例），我们利用了一种称为**梯度下降**的优化技术。梯度下降法有多种变体，一般来说，在机器学习世界中，你几乎到处都能看到它们。最重要的是，它们用于确定线性或逻辑回归等算法的最佳系数，因此，它们通常也在更复杂的技术中发挥作用，至少部分基于线性/逻辑回归（如神经网络）。

梯度下降法的一般思想是确定某些参数的变化方向和幅度，这些参数将使您朝着正确的方向移动，以优化某些度量（如误差）。想想站在什么风景上。若要向较低的标高移动，需要在向下的方向上采取步骤。这基本上就是梯度下降算法在优化参数时所做的。

让我们看一下所谓的**随机梯度下降**（**SGD**），这是一种增量梯度下降，来获得更多关于这个过程的直觉。如果您还记得，我们在[第 5 章](05.html#2TEN40-a5604e9f48ea4e63828d369cca8f0939)、*分类*中实际使用了 SGD 进行逻辑回归。在该示例中，我们实施了逻辑回归参数的训练或拟合，如下所示：

```
// logisticRegression fits a logistic regression model
// for the given data.
func logisticRegression(features *mat64.Dense, labels []float64, numSteps int, learningRate float64) []float64 {

    // Initialize random weights.
    _, numWeights := features.Dims()
    weights := make([]float64, numWeights)

    s := rand.NewSource(time.Now().UnixNano())
    r := rand.New(s)

    for idx, _ := range weights {
        weights[idx] = r.Float64()
    }

    // Iteratively optimize the weights.
    for i := 0; i < numSteps; i++ {

        // Initialize a variable to accumulate error for this iteration.
        var sumError float64

        // Make predictions for each label and accumulate error.
        for idx, label := range labels {

            // Get the features corresponding to this label.
            featureRow := mat64.Row(nil, idx, features)

            // Calculate the error for this iteration's weights.
            pred := logistic(featureRow[0]*weights[0] + featureRow[1]*weights[1])
            predError := label - pred
            sumError += math.Pow(predError, 2)

            // Update the feature weights.
            for j := 0; j < len(featureRow); j++ {
                weights[j] += learningRate * predError * pred * (1 - pred) * featureRow[j]
            }
        }
   }

   return weights
}

```

`// Iteratively optimize the weights`注释下的循环实现 SGD 以优化逻辑回归参数。让我们分离这个循环来确定到底发生了什么。

首先，我们使用当前权重和预测值与理想值（即实际观测值）之间的差值计算模型的输出：

```
// Calculate the error for this iteration's weights.
pred := logistic(featureRow[0]*weights[0] + featureRow[1]*weights[1])
predError := label - pred
sumError += math.Pow(predError, 2)
```

然后，根据 SGD，我们将根据以下公式计算参数更新（在本例中为`weights`：

![](../images/00080.jpeg)

**梯度**是问题中代价函数的数学梯度。

有关该数量的更详细数学信息可在此处找到：
[http://mathworld.wolfram.com/Gradient.html](http://mathworld.wolfram.com/Gradient.html)

然后可将更新应用于参数，如下所示：

![](../images/00081.jpeg)

对于我们的逻辑回归模型，其计算结果如下：

```
// Update the feature weights.
for j := 0; j < len(featureRow); j++ {
    weights[j] += learningRate * predError * pred * (1 - pred) * featureRow[j]
}
```

这种类型的 SGD 在机器学习中应用相当广泛。然而，在某些情况下，这种梯度下降可能导致过度拟合或陷入局部最小值/最大值（而不是找到全局最优值）。

为了解决其中一些问题，您可以使用一种称为**批量梯度下降**的梯度下降变体。在“批处理梯度下降”中，根据所有训练数据集中的梯度计算每个参数更新，而不是针对数据集的特定观察值或行计算梯度。这有助于防止过度拟合，但它也可能相当慢，并且存在内存问题，因为您需要为每个参数计算整个数据集的梯度。**小批量****梯度下降**是另一个变体，它试图保持批量梯度下降的一些优点，同时更易于计算。在小批量梯度下降中，梯度是在训练数据集的子集而不是整个训练数据集上计算的。

在逻辑回归的情况下，您可能会看到梯度上升或下降的使用，其中梯度上升与梯度下降是相同的，只是它适用于成本函数的负数。只要您保持一致，物流成本函数将为您提供这两种选择。这将在[中进一步讨论 https://stats.stackexchange.com/questions/261573/using-gradient-ascent-instead-of-gradient-descent-for-logistic-regression](https://stats.stackexchange.com/questions/261573/using-gradient-ascent-instead-of-gradient-descent-for-logistic-regression) 。

gonum 团队也已在`gonum.org/v1/gonum/optimize`中实施了梯度下降法。更多信息请参见这些文档：
[https://godoc.org/gonum.org/v1/gonum/optimize#GradientDescent](https://godoc.org/gonum.org/v1/gonum/optimize#GradientDescent)

# 熵、信息增益及相关方法

在[第 5 章](05.html#2TEN40-a5604e9f48ea4e63828d369cca8f0939)、*分类*中，我们探讨了由 if/then 语句树组成的决策树方法。决策树的这些 if/then 部分基于训练集的特征之一分割预测逻辑。在一个我们试图将医疗患者分为不健康或健康类别的示例中，决策树可能首先基于性别特征、然后基于年龄特征、然后基于体重特征，依此类推，最终以健康或不健康为目标。

算法如何选择在决策树中首先使用哪些特征？在前面的例子中，我们可以根据性别优先、体重优先和任何其他特征优先进行划分。我们需要一种以最佳方式安排拆分的方法，以便我们的模型能够做出最佳预测。

许多决策树模型实现，包括我们在[第 5 章](05.html#2TEN40-a5604e9f48ea4e63828d369cca8f0939)、*分类*中使用的一个，使用称为**熵**的数量和**信息增益**的分析来建立决策树。为了说明这个过程，让我们考虑一个例子。假设您有以下关于健康人数量与这些人的各种特征的数据：

|  | **健康** | **不健康** |
| **纯素饮食** | 5 | 2 |
| **素食** | 4 | 1 |
| **肉食饮食** | 3 | 4 |

|  | **健康** | **不健康** |
| **年龄 40 岁以上** | 3 | 5 |
| **年龄<40** | 9 | 2 |

在这里，我们的数据中有两个特征，饮食和年龄，我们想建立一个决策树，根据饮食和年龄预测人们是否健康。要做到这一点，我们需要决定是应该首先根据年龄还是饮食来划分决策树。请注意，数据中总共有 12 名健康人和 7 名不健康人。

首先，我们将计算数据中类的总体或总熵。其定义如下：

![](../images/00082.jpeg)

这里，*p<sub class="calibre25">1</sub>*、*p<sub class="calibre25">2</sub>、*等是第一类、第二类等的概率。在我们的特殊情况下（因为我们有 12 个健康人和 7 个不健康人），我们的总熵如下：

![](../images/00083.jpeg)

这个*0.95*度量值代表了我们健康数据的同质性。它介于 0 和 1 之间，高值对应的数据同质性较差。

为了确定我们是应该首先根据年龄还是饮食来划分我们的树，我们将计算这些特征中哪一个为我们提供了最多的信息。简单地说，我们将找到在该特征上分裂后给我们提供最多同质性的特征，正如前面的熵所测量的那样。这种熵的减少称为**信息增益**。

在我们的示例中，特定特征的信息增益定义如下：

![](../images/00084.jpeg)

这里，*E（健康，特征）*是关于给定特征的第二个熵度量（*年龄*或*饮食*。对于饮食，第二个指标的计算如下：

![](../images/00085.jpeg)

数量*p<sub class="calibre25">40+</sub>*和*p<sub class="calibre25"><40</sub>*是年龄为*40*+或*<40*（分别为 8/19 和 11/19）的概率。数量*E（健康，40+*和*E（健康，<40】*是健康熵（定义见上式），但仅使用分别对应于年龄*40+*和年龄*<40*的计数。

对于我们的示例数据，年龄特征的信息增益为*0.152*，饮食特征的信息增益为*0.079*。因此，我们会选择首先根据年龄特征分割决策树，因为它最大程度地提高了数据的整体同质性。

您可以在[找到更多关于基于熵构建决策树的信息 http://www.saedsayad.com/decision_tree.htm](http://www.saedsayad.com/decision_tree.htm) ，您可以在[的 Go 中看到一个示例实现 https://github.com/sjwhitworth/golearn/blob/master/trees/entropy.go](https://github.com/sjwhitworth/golearn/blob/master/trees/entropy.go) 。

# 反向传播

[第 8 章](08.html#4IRMK0-a5604e9f48ea4e63828d369cca8f0939)、*神经网络和深度学习*中包含了一个在 Go 中从头构建的神经网络示例。该神经网络包括用于训练神经网络的反向传播方法的实现，这可以在几乎任何神经网络代码中找到。我们在那一章中讨论了一些细节。然而，这种方法经常被使用，所以我们想在这里一步一步地介绍它。

为了通过反向传播训练神经网络，我们对一系列历代中的每一个历代进行以下操作：

1.  通过神经网络输入训练数据以产生输出。
2.  计算预期输出和预测输出之间的误差。
3.  基于误差，计算神经网络权重和偏差的更新。
4.  将这些更新传播回网络。

作为提醒，我们对具有单个隐藏层的网络执行此过程如下所示（其中，`wHidden`和`wOut`是我们的隐藏层和输出层权重，`bHidden`和`bOut`是我们的隐藏层和输出层偏差）：

```
105     // Define the output of the neural network.
106     output := mat.NewDense(0, 0, nil)
107 
108     // Loop over the number of epochs utilizing
109     // backpropagation to train our model.
110     for i := 0; i < nn.config.numEpochs; i++ {
111
112         // Complete the feed forward process.
113         hiddenLayerInput := mat.NewDense(0, 0, nil)
114         hiddenLayerInput.Mul(x, wHidden)
115         addBHidden := func(_, col int, v float64) float64 { return v + bHidden.At(0, col) }
116         hiddenLayerInput.Apply(addBHidden, hiddenLayerInput)
117 
118         hiddenLayerActivations := mat.NewDense(0, 0, nil)
119         applySigmoid := func(_, _ int, v float64) float64 { return sigmoid(v) }
120         hiddenLayerActivations.Apply(applySigmoid, hiddenLayerInput)
121 
122         outputLayerInput := mat.NewDense(0, 0, nil)
123         outputLayerInput.Mul(hiddenLayerActivations, wOut)
124         addBOut := func(_, col int, v float64) float64 { return v + bOut.At(0, col) }
125         outputLayerInput.Apply(addBOut, outputLayerInput)
126         output.Apply(applySigmoid, outputLayerInput)
127 
128         // Complete the backpropagation.
129         networkError := mat.NewDense(0, 0, nil)
130         networkError.Sub(y, output)
131 
132         slopeOutputLayer := mat.NewDense(0, 0, nil)
133         applySigmoidPrime := func(_, _ int, v float64) float64 { return sigmoidPrime(v) }
134         slopeOutputLayer.Apply(applySigmoidPrime, output)
135         slopeHiddenLayer := mat.NewDense(0, 0, nil)
136         slopeHiddenLayer.Apply(applySigmoidPrime, hiddenLayerActivations)
137 
138         dOutput := mat.NewDense(0, 0, nil)
139         dOutput.MulElem(networkError, slopeOutputLayer)
140         errorAtHiddenLayer := mat.NewDense(0, 0, nil)
141         errorAtHiddenLayer.Mul(dOutput, wOut.T())
142 
143         dHiddenLayer := mat.NewDense(0, 0, nil)
144         dHiddenLayer.MulElem(errorAtHiddenLayer, slopeHiddenLayer)
145 
146         // Adjust the parameters.
147         wOutAdj := mat.NewDense(0, 0, nil)
148         wOutAdj.Mul(hiddenLayerActivations.T(), dOutput)
149         wOutAdj.Scale(nn.config.learningRate, wOutAdj)
150         wOut.Add(wOut, wOutAdj)
151 
152         bOutAdj, err := sumAlongAxis(0, dOutput)
153         if err != nil {
154             return err
155         }
156         bOutAdj.Scale(nn.config.learningRate, bOutAdj)
157         bOut.Add(bOut, bOutAdj)
158 
159         wHiddenAdj := mat.NewDense(0, 0, nil)
160         wHiddenAdj.Mul(x.T(), dHiddenLayer)
161         wHiddenAdj.Scale(nn.config.learningRate, wHiddenAdj)
162         wHidden.Add(wHidden, wHiddenAdj)
163 
164         bHiddenAdj, err := sumAlongAxis(0, dHiddenLayer)
165         if err != nil {
166             return err
167         }
168         bHiddenAdj.Scale(nn.config.learningRate, bHiddenAdj)
169         bHidden.Add(bHidden, bHiddenAdj)
170     }
```

让我们详细分析一下这个实现，以确切地了解发生了什么。

产生输出的前馈过程执行以下操作：

1.  将输入数据乘以隐藏层权重，添加隐藏层偏差，并应用 sigmoid 激活函数计算隐藏层的输出`hiddenLayerActivations`（前面代码段中的第 112 至 120 行）。
2.  将`hiddenLayerActivations`乘以输出层权重，然后添加输出层偏差，并应用 sigmoid 激活函数来计算`output`（第 122 至 126 行）。

请注意，在前馈过程中，我们从输入层的输入数据开始，通过隐藏层前进，直到到达输出。

在前馈过程之后，我们需要计算对权重和偏差的最佳更新。正如您在阅读本附录的梯度下降部分后所期望的那样，梯度下降非常适合找到这些权重和偏差。前面代码段中的第 129 行到第 144 行实现了 SGD。

最后，我们需要通过第 147 到 169 行中的网络向后应用这些更新。这是更新的反向传播，为反向传播命名。这个过程没有什么特别之处，我们只执行以下操作：

1.  将计算出的更新应用于输出权重和偏差（第 147 至 157 行）。
2.  将计算出的更新应用于隐藏层权重和偏移（第 159 至 169 行）。

请注意，我们是如何从输出开始，然后应用更改返回到输入的。

您可以在这里找到关于反向传播的非常详细的讨论，包括数学证明：
﻿ [http://neuralnetworksanddeeplearning.com/chap2.html](http://neuralnetworksanddeeplearning.com/chap2.html)

在大卫·鲁默哈特、杰弗里·辛顿和罗纳德·威廉姆斯 1986 年发表论文之后，反向传播开始被广泛使用。尽管该方法在整个行业的神经网络中都得到了应用，但杰弗里·辛顿（Geoffrey Hinton）最近表示，他对反向传播非常怀疑，并建议我们需要努力寻找替代方法。